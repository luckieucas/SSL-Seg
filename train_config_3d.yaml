exp: "test" # threshhold for model1 and model2 are 0.95
method: CCRPS # use which semi-supervised method [Baseline,MT,EM,C3PS,DAN,CPS,UAMT,ConNet,McNet,CVCL,CCRPS,CVCL_partial,CAML]
train_3D: True # whether to train 3D models
backbone: unet_3D_old #[unet_3D_old, McNet,unet_3D_cl, unet, caml ]# backbone model
backbone2: unet_3D_sr #[unet_3D_condtion_decoder] for C3PS, [unet_3D_sr] for CCRPS # backbone for second network [unet_3D_condtion_decoder,unet_3D_condtion,Unet3DConditionBottom]
dataset_name: LA #[BCV, MMWHS, LA]
gpu: '0'
#root_path: ../../dataset/Task012_Heart

# continue training setting
continue_wandb: False
continue_training: True
wandb_id: "2jkdqxmi"
model_checkpoint: "/projects/weilab/liupeng/semi-seg/model/LA_8_CCRPS_test_SGD_SGD/unet_3D_old/model1_iter_17600_dice_0.9036.pth"
model2_checkpoint: "/projects/weilab/liupeng/semi-seg/model/LA_8_CCRPS_test_SGD_SGD/unet_3D_old/model2_iter_17600_dice_0.9036.pth"

current_iter_num: 17600

# semi supervised learning setting
began_semi_iter: 4000  #8000 #2000
began_condition_iter: 3000 #4000

# evaluation settings
began_eval_iter: 2000 # 300
val_freq: 400 #200

# training settings
save_checkpoint_freq: 200
max_iterations: 20000
use_CAC: True   # whether use Context-Aware-Consistency
use_PL: False # whether use partial label
deterministic: 1
initial_lr: 0.01
initial2_lr: 0.01 # for second network
optimizer_type: 'SGD' # ['SGD' or 'Adam']
optimizer2_type: 'SGD' # for second network
model1_thresh: 0.90 #threshhold for model1
model2_thresh: 0.95 # threshhold for model2
seed: 1337
ema_decay: 0.99
consistency_type: mse
consistency: 0.1 #0.1 1.0 for McNet
consistency_rampup: 200.0
weight_decay: 0.00001 #0.00001
lr_scheduler_patience: 30
lr_scheduler_eps: 0.001
show_img_freq: 1000

METHOD:
  ICT:
    ict_alpha: 0.2
  MT:
  UAMT:
  CPS:
  DAN:
  EM:
  Baseline:
  URPC:
  C3PS: # config for Context-Aware-Consistency
    stride: 2
    iou_bound_low: 0.1
    iou_bound_high: 0.9
    con_list: [1,2,3,4] # specificy condition list
    addition_con_list: []
  ConNet: # config for Context-Aware-Consistency
    stride: 2
    iou_bound_low: 0.1
    iou_bound_high: 0.9
    con_list: [1,2,3,4,5,6,7] # specificy condition list
    addition_con_list: [8]
  McNet:
  CVCL:
    stride: 8
    step_save: 2
    iou_bound_low: 0.1
    iou_bound_high: 0.9
    con_list: [1,2,3,4,5,6,7] # specificy condition list
    addition_con_list: [8]
    threshold: 0.5
  CVCL_partial:
    stride: 8
    step_save: 2
    iou_bound_low: 0.1
    iou_bound_high: 0.9
    con_list: [1,2,3,4,5] # specificy condition list
    addition_con_list: [8]
    threshold: 0.5
    began_partial: 4000
  CCRPS: # config for Context-Aware-Consistency
    stride: 2
    iou_bound_low: 0.1
    iou_bound_high: 1.01
    patch_size_large: [128,256,256] #[144, 256, 320]
  CTCT:
    cache_mode: part
    zip: True
    accumulation_steps:
    use_checkpoint: False 
    amp_opt_level: O1
    tag:
    eval: False 
    throughput: False
  CAML:


DATASET:
  labeled_num: 8
  labeled_num_pl: 60 # labeled number for partial labeled data
  labeled_bs: 1 #1
  batch_size: 2 #2
  patch_size: [80,112,112] #[224, 224] #[96,112,112] # for DAN #[80,112,112] #[96,160,160]
  cutout: True # do random cutout
  rotate_trans: True # do random rotate
  scale_trans: True # do random scale
  random_rotflip: False # do random rotation and flip
  edge_prob: 0.1 # prob to learn edge slice
  normalization: 'Zscore'
  LA: # config for LA dataset
    num_classes: 2
    class_name_list: ['LA']
    weights: [1.0]
    train_list: "/projects/weilab/liupeng/dataset/ssl_seg/LA_dataset/TrainingSet/LA_train.txt"
    train_list_pl: "/projects/weilab/liupeng/dataset/ssl_seg/LA_dataset/test.txt" # train list for partial labeled data
    test_list: "/projects/weilab/liupeng/dataset/ssl_seg/LA_dataset/TrainingSet/LA_test.txt"
    training_data_num: 80
    testing_data_num: 20
    cut_upper: 300 # 1000  200 for urpc
    cut_lower: -200 # -1000 -68 for urpc 
  MMWHS: # config for MMWHS dataset
    num_classes: 8
    class_name_list: ['MYO', 'LA', 'LV', 'RA', 'AA', 'PA', 'RV','Foreground']
    weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
    train_list: "/projects/weilab/liupeng/dataset/ssl_seg/Task012_Heart/MMWHS_train.txt" #"../data/MMWHS/MMWHS_train.txt"
    train_list_pl: "../data/Pancreas/pancreas_test.txt" # train list for partial labeled data
    test_list: "/projects/weilab/liupeng/dataset/ssl_seg/Task012_Heart/MMWHS_test.txt" #"../data/MMWHS/MMWHS_test.txt"
    training_data_num: 14
    testing_data_num: 6
    cut_upper: 300 # 1000  200 for urpc
    cut_lower: -200 # -1000 -68 for urpc
  MMWHS_MR: # config for MMWHS dataset
    num_classes: 8
    train_list: "../data/MMWHS_MR/train.txt"
    test_list: "../data/MMWHS_MR/test.txt"
    training_data_num: 14
    testing_data_num: 6
    cut_upper: 1000
    cut_lower: -1000
  BCV: # config for BCV dataset
    num_classes: 6
    class_name_list: ['Spleen', 'Right_Kidney', 'Left_Kidney','Liver','Pancreas','Foreground']
    weights: [1.0,1.0,1.0,1.0,1.0] #[0.2,0.2,0.2,0.1,0.3]
    train_list: "/projects/weilab/liupeng/dataset/ssl_seg/Task11_BCV/train.txt"
    train_list_pl: "/projects/weilab/liupeng/dataset/ssl_seg/Pancreas/pancreas_test.txt" # train list for partial labeled data
    test_list: "/projects/weilab/liupeng/dataset/ssl_seg/Task11_BCV/test.txt"
    training_data_num: 24
    testing_data_num: 6 
    cut_upper: 275 #200
    cut_lower: -125 #-68
  FLARE: # config for BCV dataset
    num_classes: 5
    weights: [1.0,1.0,1.0,1.0]
    class_name_list: ['Liver','Kidney','Spleen', 'Pancreas','Foreground']
    train_list: "../data/AbdomenCT-1K/Flare_train.txt"
    test_list: "../data/AbdomenCT-1K/Flare_test.txt"
    train_list_pl: "../data/Pancreas/pancreas_test.txt"
    training_data_num: 200
    testing_data_num: 161
    cut_upper: 275 #200
    cut_lower: -125 #-68
  FLARE_FR: # config for BCV dataset
    num_classes: 5
    weights: [1.0,1.0,1.0,1.0]
    class_name_list: ['Liver','Kidney','Spleen', 'Pancreas','Foreground']
    train_list: "../data/AbdomenCT-1K/Flare_train_fullres.txt"
    test_list: "../data/AbdomenCT-1K/Flare_test_fullres.txt"
    train_list_pl: "../data/Pancreas/pancreas_test.txt"
    training_data_num: 200
    testing_data_num: 161
    cut_upper: 275 #200
    cut_lower: -125 #-68
  FLARE_MR: # config for BCV dataset
    num_classes: 5
    weights: [1.0,1.0,1.0,1.0]
    class_name_list: ['Liver','Kidney','Spleen', 'Pancreas','Foreground']
    train_list: "../data/AbdomenCT-1K/Flare_train_midres.txt"
    test_list: "../data/AbdomenCT-1K/Flare_test_midres.txt"
    train_list_pl: "../data/Pancreas/pancreas_test.txt"
    training_data_num: 200
    testing_data_num: 161
    cut_upper: 275 #200
    cut_lower: -125 #-68

model:
  # model class, e.g. UNet3D, ResidualUNet3D
  name: Semi3DUNet
  # number of input channels to the model
  in_channels: 1
  # number of output channels
  out_channels: 8
  # determines the order of operators in a single layer (gcr - GroupNorm+Conv3d+ReLU)
  layer_order: gcr
  # feature maps scale factor
  f_maps: 16 #16
  # number of levels
  num_levels: 5 #4
  # number of groups in the groupnorm
  num_groups: 8
  # apply element-wise nn.Sigmoid after the final 1x1 convolution, otherwise apply nn.Softmax
  final_sigmoid: False
  # if True applies the final normalization layer (sigmoid or softmax), otherwise the networks returns the output from the final convolution layer; use False for regression problems, e.g. de-noising
  is_segmentation: true